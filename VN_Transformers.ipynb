{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"VN_Transformers.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Swag-z2OssCL","executionInfo":{"status":"ok","timestamp":1614950467494,"user_tz":-420,"elapsed":31624,"user":{"displayName":"Nguy Huu Loc B1706606","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBw3CeyVXGS902KjXF0kx3M8aW-yGmbXac6bMN=s64","userId":"07558350334874798256"}},"outputId":"86fd7f6e-dc62-4605-afce-0596a465d4ca"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eUuJNbc5_Ey6","executionInfo":{"status":"ok","timestamp":1614950469855,"user_tz":-420,"elapsed":33977,"user":{"displayName":"Nguy Huu Loc B1706606","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBw3CeyVXGS902KjXF0kx3M8aW-yGmbXac6bMN=s64","userId":"07558350334874798256"}}},"source":["import tensorflow as tf\r\n","from __future__ import absolute_import, division, print_function, unicode_literals\r\n","import sys\r\n","import tensorflow_datasets as tfds\r\n","\r\n","import os\r\n","import re\r\n","import numpy as np\r\n","from time import time\r\n","import matplotlib.pyplot as plt\r\n","\r\n","tf.random.set_seed(1234)\r\n","AUTO = tf.data.experimental.AUTOTUNE"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"fVekS8Nknhgw","executionInfo":{"status":"ok","timestamp":1614950469861,"user_tz":-420,"elapsed":33976,"user":{"displayName":"Nguy Huu Loc B1706606","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBw3CeyVXGS902KjXF0kx3M8aW-yGmbXac6bMN=s64","userId":"07558350334874798256"}}},"source":["from tensorflow.keras.preprocessing.sequence import pad_sequences"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"LCTsI00dk27x"},"source":["try:\r\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\r\n","    print('Running on TPU {}'.format(tpu.cluster_spec().as_dict()['worker']))\r\n","except ValueError:\r\n","    tpu = None\r\n","\r\n","if tpu:\r\n","    tf.config.experimental_connect_to_cluster(tpu)\r\n","    tf.tpu.experimental.initialize_tpu_system(tpu)\r\n","    strategy = tf.distribute.experimental.TPUStrategy(tpu)\r\n","else:\r\n","    strategy = tf.distribute.get_strategy()\r\n","\r\n","print(\"REPLICAS: {}\".format(strategy.num_replicas_in_sync))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cxbEFm_LlH43","executionInfo":{"status":"ok","timestamp":1614957956153,"user_tz":-420,"elapsed":707,"user":{"displayName":"Nguy Huu Loc B1706606","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBw3CeyVXGS902KjXF0kx3M8aW-yGmbXac6bMN=s64","userId":"07558350334874798256"}}},"source":["# Maximum sentence length\r\n","MAX_LENGTH = 25\r\n","\r\n","# Maximum number of samples to preprocess\r\n","MAX_SAMPLES = 50000\r\n","\r\n","# For tf.data.Dataset\r\n","BATCH_SIZE = 64 * strategy.num_replicas_in_sync\r\n","BUFFER_SIZE = 20000\r\n","\r\n","# For Transformer\r\n","NUM_LAYERS = 2\r\n","D_MODEL = 256\r\n","NUM_HEADS = 8\r\n","UNITS = 512\r\n","DROPOUT = 0.1\r\n","EPOCHS = 150"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8GGDWrtEMf5h","executionInfo":{"status":"ok","timestamp":1614957958041,"user_tz":-420,"elapsed":793,"user":{"displayName":"Nguy Huu Loc B1706606","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBw3CeyVXGS902KjXF0kx3M8aW-yGmbXac6bMN=s64","userId":"07558350334874798256"}},"outputId":"31b12422-6eaa-460b-db12-d9c20435edc6"},"source":["%cd '/content/drive/MyDrive/LVTN_2021/Colab Notebook/data_VN/data/vn_data_2'\n","!ls"],"execution_count":39,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/LVTN_2021/Colab Notebook/data_VN/data/vn_data_2\n","data_2.ipynb\t\t vn_data_2.1_tmp.txt  vn_questions_list_2_1.txt\n","saved_weights_tpu_1.h5\t vn_data_2.1.txt\n","vn_answers_list_2_1.txt  vn_data_2.2.txt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ybm2CJf7lK_e","executionInfo":{"status":"ok","timestamp":1614957977437,"user_tz":-420,"elapsed":1536,"user":{"displayName":"Nguy Huu Loc B1706606","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBw3CeyVXGS902KjXF0kx3M8aW-yGmbXac6bMN=s64","userId":"07558350334874798256"}}},"source":["questions = open('vn_questions_list_2_1.txt', encoding='utf-8', errors='ignore').read().split('\\n')\r\n","answers   = open('vn_answers_list_2_1.txt', encoding='utf-8', errors='ignore').read().split('\\n')"],"execution_count":43,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RQ6fk8cHtT0P","executionInfo":{"status":"ok","timestamp":1614957972167,"user_tz":-420,"elapsed":665,"user":{"displayName":"Nguy Huu Loc B1706606","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBw3CeyVXGS902KjXF0kx3M8aW-yGmbXac6bMN=s64","userId":"07558350334874798256"}},"outputId":"cbe1adbb-6f91-4e49-e467-98d1d525098e"},"source":["print(\"VN Questions length: \"+str(len(questions)))\n","print(\"VN Answers length: \"+str(len(answers)))"],"execution_count":41,"outputs":[{"output_type":"stream","text":["VN Questions length: 772576\n","VN Answers length: 772576\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"siZO8z77t4I4","executionInfo":{"status":"ok","timestamp":1614958082275,"user_tz":-420,"elapsed":102515,"user":{"displayName":"Nguy Huu Loc B1706606","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBw3CeyVXGS902KjXF0kx3M8aW-yGmbXac6bMN=s64","userId":"07558350334874798256"}}},"source":["# Build tokenizer using tfds for both questions and answers\r\n","tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\r\n","    questions + answers, target_vocab_size=2**13)\r\n","\r\n","# Define start and end token to indicate the start and end of a sentence\r\n","START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\r\n","\r\n","# Vocabulary size plus start and end token\r\n","VOCAB_SIZE = tokenizer.vocab_size + 2"],"execution_count":44,"outputs":[]},{"cell_type":"code","metadata":{"id":"QSgvqaaBlUXA","executionInfo":{"status":"ok","timestamp":1614958154785,"user_tz":-420,"elapsed":45655,"user":{"displayName":"Nguy Huu Loc B1706606","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBw3CeyVXGS902KjXF0kx3M8aW-yGmbXac6bMN=s64","userId":"07558350334874798256"}}},"source":["def tokenize_and_filter(inputs, outputs):\r\n","  tokenized_inputs, tokenized_outputs = [], []\r\n","  \r\n","  for (sentence1, sentence2) in zip(inputs, outputs):\r\n","    # tokenize sentence\r\n","    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\r\n","    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\r\n","    # check tokenized sentence max length\r\n","    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\r\n","      tokenized_inputs.append(sentence1)\r\n","      tokenized_outputs.append(sentence2)\r\n","  \r\n","  # pad tokenized sentences\r\n","  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\r\n","      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\r\n","  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\r\n","      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\r\n","  \r\n","  return tokenized_inputs, tokenized_outputs\r\n","\r\n","\r\n","questions, answers = tokenize_and_filter(questions, answers)"],"execution_count":45,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Df5-CCXOnT9o","executionInfo":{"status":"ok","timestamp":1614958817822,"user_tz":-420,"elapsed":735,"user":{"displayName":"Nguy Huu Loc B1706606","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBw3CeyVXGS902KjXF0kx3M8aW-yGmbXac6bMN=s64","userId":"07558350334874798256"}},"outputId":"0332a3fc-6e1b-4ec3-f67a-b7a24ae2f545"},"source":["print('Vocab size: {}'.format(VOCAB_SIZE))\r\n","print('Number of samples: {}'.format(len(answers)))"],"execution_count":46,"outputs":[{"output_type":"stream","text":["Vocab size: 8153\n","Number of samples: 768059\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kGBTUQB7oGyG","executionInfo":{"status":"ok","timestamp":1614958827940,"user_tz":-420,"elapsed":2792,"user":{"displayName":"Nguy Huu Loc B1706606","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBw3CeyVXGS902KjXF0kx3M8aW-yGmbXac6bMN=s64","userId":"07558350334874798256"}}},"source":["dataset = tf.data.Dataset.from_tensor_slices((\r\n","    {\r\n","        'inputs': questions,\r\n","        'dec_inputs': answers[:, :-1]\r\n","    },\r\n","    {\r\n","        'outputs': answers[:, 1:]\r\n","    },\r\n","))\r\n","\r\n","dataset = dataset.cache()\r\n","dataset = dataset.shuffle(BUFFER_SIZE)\r\n","dataset = dataset.batch(BATCH_SIZE)\r\n","dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"],"execution_count":47,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ei29BKFcoKOu","executionInfo":{"status":"ok","timestamp":1614958830186,"user_tz":-420,"elapsed":677,"user":{"displayName":"Nguy Huu Loc B1706606","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBw3CeyVXGS902KjXF0kx3M8aW-yGmbXac6bMN=s64","userId":"07558350334874798256"}},"outputId":"8c54e1fa-05ad-42f1-d32a-e01a5154c90f"},"source":["print(dataset)"],"execution_count":48,"outputs":[{"output_type":"stream","text":["<PrefetchDataset shapes: ({inputs: (None, 25), dec_inputs: (None, 24)}, {outputs: (None, 24)}), types: ({inputs: tf.int32, dec_inputs: tf.int32}, {outputs: tf.int32})>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uSz_X8lfoV6l","executionInfo":{"status":"ok","timestamp":1614950641271,"user_tz":-420,"elapsed":205286,"user":{"displayName":"Nguy Huu Loc B1706606","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBw3CeyVXGS902KjXF0kx3M8aW-yGmbXac6bMN=s64","userId":"07558350334874798256"}}},"source":["def scaled_dot_product_attention(query, key, value, mask):\r\n","  \"\"\"Calculate the attention weights. \"\"\"\r\n","  matmul_qk = tf.matmul(query, key, transpose_b=True)\r\n","\r\n","  # scale matmul_qk\r\n","  depth = tf.cast(tf.shape(key)[-1], tf.float32)\r\n","  logits = matmul_qk / tf.math.sqrt(depth)\r\n","\r\n","  # add the mask to zero out padding tokens\r\n","  if mask is not None:\r\n","    logits += (mask * -1e9)\r\n","\r\n","  # softmax is normalized on the last axis (seq_len_k)\r\n","  attention_weights = tf.nn.softmax(logits, axis=-1)\r\n","\r\n","  output = tf.matmul(attention_weights, value)\r\n","\r\n","  return output"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"yPSkAK35oaac","executionInfo":{"status":"ok","timestamp":1614950641272,"user_tz":-420,"elapsed":205284,"user":{"displayName":"Nguy Huu Loc B1706606","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBw3CeyVXGS902KjXF0kx3M8aW-yGmbXac6bMN=s64","userId":"07558350334874798256"}}},"source":["class MultiHeadAttention(tf.keras.layers.Layer):\r\n","\r\n","  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\r\n","    super(MultiHeadAttention, self).__init__(name=name)\r\n","    self.num_heads = num_heads\r\n","    self.d_model = d_model\r\n","\r\n","    assert d_model % self.num_heads == 0\r\n","\r\n","    self.depth = d_model // self.num_heads\r\n","\r\n","    self.query_dense = tf.keras.layers.Dense(units=d_model)\r\n","    self.key_dense = tf.keras.layers.Dense(units=d_model)\r\n","    self.value_dense = tf.keras.layers.Dense(units=d_model)\r\n","\r\n","    self.dense = tf.keras.layers.Dense(units=d_model)\r\n","  \r\n","  def get_config(self):\r\n","        config = super(MultiHeadAttention,self).get_config()\r\n","        config.update({\r\n","            'num_heads':self.num_heads,\r\n","            'd_model':self.d_model,\r\n","        })\r\n","        return config\r\n","\r\n","  def split_heads(self, inputs, batch_size):\r\n","    inputs = tf.keras.layers.Lambda(lambda inputs:tf.reshape(\r\n","        inputs, shape=(batch_size, -1, self.num_heads, self.depth)))(inputs)\r\n","    return tf.keras.layers.Lambda(lambda inputs: tf.transpose(inputs, perm=[0, 2, 1, 3]))(inputs)\r\n","\r\n","  def call(self, inputs):\r\n","    query, key, value, mask = inputs['query'], inputs['key'], inputs[\r\n","        'value'], inputs['mask']\r\n","    batch_size = tf.shape(query)[0]\r\n","\r\n","    # linear layers\r\n","    query = self.query_dense(query)\r\n","    key = self.key_dense(key)\r\n","    value = self.value_dense(value)\r\n","\r\n","    # split heads\r\n","    query = self.split_heads(query, batch_size)\r\n","    key = self.split_heads(key, batch_size)\r\n","    value = self.split_heads(value, batch_size)\r\n","\r\n","    # scaled dot-product attention\r\n","    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\r\n","    scaled_attention = tf.keras.layers.Lambda(lambda scaled_attention: tf.transpose(\r\n","        scaled_attention, perm=[0, 2, 1, 3]))(scaled_attention)\r\n","\r\n","    # concatenation of heads\r\n","    concat_attention = tf.keras.layers.Lambda(lambda scaled_attention: tf.reshape(scaled_attention,\r\n","                                  (batch_size, -1, self.d_model)))(scaled_attention)\r\n","\r\n","    # final linear layer\r\n","    outputs = self.dense(concat_attention)\r\n","\r\n","    return outputs    "],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"mVbI-h2eofFG","executionInfo":{"status":"ok","timestamp":1614950641273,"user_tz":-420,"elapsed":205281,"user":{"displayName":"Nguy Huu Loc B1706606","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBw3CeyVXGS902KjXF0kx3M8aW-yGmbXac6bMN=s64","userId":"07558350334874798256"}}},"source":["def create_padding_mask(x):\r\n","  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\r\n","  # (batch_size, 1, 1, sequence length)\r\n","  return mask[:, tf.newaxis, tf.newaxis, :]"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7iFv9wAhohmE","executionInfo":{"status":"ok","timestamp":1614950641274,"user_tz":-420,"elapsed":205266,"user":{"displayName":"Nguy Huu Loc B1706606","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBw3CeyVXGS902KjXF0kx3M8aW-yGmbXac6bMN=s64","userId":"07558350334874798256"}},"outputId":"9d28183d-b534-4515-8282-0c92259f345e"},"source":["print(create_padding_mask(tf.constant([[1, 2, 0, 3, 0], [0, 0, 0, 4, 5]])))"],"execution_count":17,"outputs":[{"output_type":"stream","text":["tf.Tensor(\n","[[[[0. 0. 1. 0. 1.]]]\n","\n","\n"," [[[1. 1. 1. 0. 0.]]]], shape=(2, 1, 1, 5), dtype=float32)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FKE163aMolLe","executionInfo":{"status":"ok","timestamp":1614950641275,"user_tz":-420,"elapsed":205263,"user":{"displayName":"Nguy Huu Loc B1706606","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBw3CeyVXGS902KjXF0kx3M8aW-yGmbXac6bMN=s64","userId":"07558350334874798256"}}},"source":["def create_look_ahead_mask(x):\r\n","  seq_len = tf.shape(x)[1]\r\n","  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\r\n","  padding_mask = create_padding_mask(x)\r\n","  return tf.maximum(look_ahead_mask, padding_mask)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b1PEhsnnomIE","executionInfo":{"status":"ok","timestamp":1614950641276,"user_tz":-420,"elapsed":205249,"user":{"displayName":"Nguy Huu Loc B1706606","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBw3CeyVXGS902KjXF0kx3M8aW-yGmbXac6bMN=s64","userId":"07558350334874798256"}},"outputId":"4a086ea0-a1a0-43cd-ea4d-53e5b34716de"},"source":["print(create_look_ahead_mask(tf.constant([[1, 2, 0, 4, 5]])))"],"execution_count":19,"outputs":[{"output_type":"stream","text":["tf.Tensor(\n","[[[[0. 1. 1. 1. 1.]\n","   [0. 0. 1. 1. 1.]\n","   [0. 0. 1. 1. 1.]\n","   [0. 0. 1. 0. 1.]\n","   [0. 0. 1. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mmu8maoTopt-","executionInfo":{"status":"ok","timestamp":1614950641277,"user_tz":-420,"elapsed":205246,"user":{"displayName":"Nguy Huu Loc B1706606","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBw3CeyVXGS902KjXF0kx3M8aW-yGmbXac6bMN=s64","userId":"07558350334874798256"}}},"source":["class PositionalEncoding(tf.keras.layers.Layer):\r\n","\r\n","  def __init__(self, position, d_model):\r\n","    super(PositionalEncoding, self).__init__()\r\n","    self.pos_encoding = self.positional_encoding(position, d_model)\r\n","  \r\n","  def get_config(self):\r\n","\r\n","        config = super(PositionalEncoding, self).get_config()\r\n","        config.update({\r\n","            'position': self.position,\r\n","            'd_model': self.d_model,\r\n","            \r\n","        })\r\n","        return config\r\n","\r\n","  def get_angles(self, position, i, d_model):\r\n","    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\r\n","    return position * angles\r\n","\r\n","  def positional_encoding(self, position, d_model):\r\n","    angle_rads = self.get_angles(\r\n","        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\r\n","        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\r\n","        d_model=d_model)\r\n","    # apply sin to even index in the array\r\n","    sines = tf.math.sin(angle_rads[:, 0::2])\r\n","    # apply cos to odd index in the array\r\n","    cosines = tf.math.cos(angle_rads[:, 1::2])\r\n","\r\n","    pos_encoding = tf.concat([sines, cosines], axis=-1)\r\n","    pos_encoding = pos_encoding[tf.newaxis, ...]\r\n","    return tf.cast(pos_encoding, tf.float32)\r\n","\r\n","  def call(self, inputs):\r\n","    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"N_JIHWRooy-E","executionInfo":{"status":"ok","timestamp":1614950641279,"user_tz":-420,"elapsed":205245,"user":{"displayName":"Nguy Huu Loc B1706606","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBw3CeyVXGS902KjXF0kx3M8aW-yGmbXac6bMN=s64","userId":"07558350334874798256"}}},"source":["def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\r\n","  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\r\n","  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\r\n","\r\n","  attention = MultiHeadAttention(\r\n","      d_model, num_heads, name=\"attention\")({\r\n","          'query': inputs,\r\n","          'key': inputs,\r\n","          'value': inputs,\r\n","          'mask': padding_mask\r\n","      })\r\n","  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\r\n","  add_attention = tf.keras.layers.add([inputs,attention])\r\n","  attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(add_attention)\r\n","\r\n","  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\r\n","  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\r\n","  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\r\n","  add_attention = tf.keras.layers.add([attention,outputs])\r\n","  outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(add_attention)\r\n","\r\n","  return tf.keras.Model(\r\n","      inputs=[inputs, padding_mask], outputs=outputs, name=name)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"OynuxKEjo9ic","executionInfo":{"status":"ok","timestamp":1614950641281,"user_tz":-420,"elapsed":205243,"user":{"displayName":"Nguy Huu Loc B1706606","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBw3CeyVXGS902KjXF0kx3M8aW-yGmbXac6bMN=s64","userId":"07558350334874798256"}}},"source":["def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\r\n","  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\r\n","  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\r\n","\r\n","  attention = MultiHeadAttention(\r\n","      d_model, num_heads, name=\"attention\")({\r\n","          'query': inputs,\r\n","          'key': inputs,\r\n","          'value': inputs,\r\n","          'mask': padding_mask\r\n","      })\r\n","  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\r\n","  add_attention = tf.keras.layers.add([inputs,attention])\r\n","  attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(add_attention)\r\n","\r\n","  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\r\n","  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\r\n","  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\r\n","  add_attention = tf.keras.layers.add([attention,outputs])\r\n","  outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(add_attention)\r\n","\r\n","  return tf.keras.Model(\r\n","      inputs=[inputs, padding_mask], outputs=outputs, name=name)"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"0xuNkomgpNRV","executionInfo":{"status":"ok","timestamp":1614950641282,"user_tz":-420,"elapsed":205241,"user":{"displayName":"Nguy Huu Loc B1706606","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBw3CeyVXGS902KjXF0kx3M8aW-yGmbXac6bMN=s64","userId":"07558350334874798256"}}},"source":["def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\r\n","  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\r\n","  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\r\n","  look_ahead_mask = tf.keras.Input(\r\n","      shape=(1, None, None), name=\"look_ahead_mask\")\r\n","  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\r\n","\r\n","  attention1 = MultiHeadAttention(\r\n","      d_model, num_heads, name=\"attention_1\")(inputs={\r\n","          'query': inputs,\r\n","          'key': inputs,\r\n","          'value': inputs,\r\n","          'mask': look_ahead_mask\r\n","      })\r\n","  add_attention = tf.keras.layers.add([attention1,inputs])    \r\n","  attention1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(add_attention)\r\n","\r\n","  attention2 = MultiHeadAttention(\r\n","      d_model, num_heads, name=\"attention_2\")(inputs={\r\n","          'query': attention1,\r\n","          'key': enc_outputs,\r\n","          'value': enc_outputs,\r\n","          'mask': padding_mask\r\n","      })\r\n","  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\r\n","  add_attention = tf.keras.layers.add([attention2,attention1])\r\n","  attention2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(add_attention)\r\n","\r\n","  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\r\n","  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\r\n","  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\r\n","  add_attention = tf.keras.layers.add([outputs,attention2])\r\n","  outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(add_attention)\r\n","\r\n","  return tf.keras.Model(\r\n","      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\r\n","      outputs=outputs,\r\n","      name=name)"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"VCqkzchZpUAk","executionInfo":{"status":"ok","timestamp":1614950641723,"user_tz":-420,"elapsed":205678,"user":{"displayName":"Nguy Huu Loc B1706606","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBw3CeyVXGS902KjXF0kx3M8aW-yGmbXac6bMN=s64","userId":"07558350334874798256"}}},"source":["def encoder(vocab_size,\r\n","            num_layers,\r\n","            units,\r\n","            d_model,\r\n","            num_heads,\r\n","            dropout,\r\n","            name=\"encoder\"):\r\n","  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\r\n","  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\r\n","\r\n","  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\r\n","  embeddings *= tf.keras.layers.Lambda(lambda d_model: tf.math.sqrt(tf.cast(d_model, tf.float32)))(d_model)\r\n","  embeddings = PositionalEncoding(vocab_size,d_model)(embeddings)\r\n","\r\n","  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\r\n","\r\n","  for i in range(num_layers):\r\n","    outputs = encoder_layer(\r\n","        units=units,\r\n","        d_model=d_model,\r\n","        num_heads=num_heads,\r\n","        dropout=dropout,\r\n","        name=\"encoder_layer_{}\".format(i),\r\n","    )([outputs, padding_mask])\r\n","\r\n","  return tf.keras.Model(\r\n","      inputs=[inputs, padding_mask], outputs=outputs, name=name)"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"avIpXFO0pVAU","executionInfo":{"status":"ok","timestamp":1614950641724,"user_tz":-420,"elapsed":205674,"user":{"displayName":"Nguy Huu Loc B1706606","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBw3CeyVXGS902KjXF0kx3M8aW-yGmbXac6bMN=s64","userId":"07558350334874798256"}}},"source":["def decoder(vocab_size,\r\n","            num_layers,\r\n","            units,\r\n","            d_model,\r\n","            num_heads,\r\n","            dropout,\r\n","            name='decoder'):\r\n","  inputs = tf.keras.Input(shape=(None,), name='inputs')\r\n","  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\r\n","  look_ahead_mask = tf.keras.Input(\r\n","      shape=(1, None, None), name='look_ahead_mask')\r\n","  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\r\n","  \r\n","  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\r\n","  embeddings *= tf.keras.layers.Lambda(lambda d_model: tf.math.sqrt(tf.cast(d_model, tf.float32)))(d_model)\r\n","  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\r\n","\r\n","  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\r\n","\r\n","  for i in range(num_layers):\r\n","    outputs = decoder_layer(\r\n","        units=units,\r\n","        d_model=d_model,\r\n","        num_heads=num_heads,\r\n","        dropout=dropout,\r\n","        name='decoder_layer_{}'.format(i),\r\n","    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\r\n","\r\n","  return tf.keras.Model(\r\n","      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\r\n","      outputs=outputs,\r\n","      name=name)"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"xOeVjAFWpcC8","executionInfo":{"status":"ok","timestamp":1614950641725,"user_tz":-420,"elapsed":205671,"user":{"displayName":"Nguy Huu Loc B1706606","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBw3CeyVXGS902KjXF0kx3M8aW-yGmbXac6bMN=s64","userId":"07558350334874798256"}}},"source":["def transformer(vocab_size,\r\n","                num_layers,\r\n","                units,\r\n","                d_model,\r\n","                num_heads,\r\n","                dropout,\r\n","                name=\"transformer\"):\r\n","  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\r\n","  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\r\n","\r\n","  enc_padding_mask = tf.keras.layers.Lambda(\r\n","      create_padding_mask, output_shape=(1, 1, None),\r\n","      name='enc_padding_mask')(inputs)\r\n","  # mask the future tokens for decoder inputs at the 1st attention block\r\n","  look_ahead_mask = tf.keras.layers.Lambda(\r\n","      create_look_ahead_mask,\r\n","      output_shape=(1, None, None),\r\n","      name='look_ahead_mask')(dec_inputs)\r\n","  # mask the encoder outputs for the 2nd attention block\r\n","  dec_padding_mask = tf.keras.layers.Lambda(\r\n","      create_padding_mask, output_shape=(1, 1, None),\r\n","      name='dec_padding_mask')(inputs)\r\n","\r\n","  enc_outputs = encoder(\r\n","      vocab_size=vocab_size,\r\n","      num_layers=num_layers,\r\n","      units=units,\r\n","      d_model=d_model,\r\n","      num_heads=num_heads,\r\n","      dropout=dropout,\r\n","  )(inputs=[inputs, enc_padding_mask])\r\n","\r\n","  dec_outputs = decoder(\r\n","      vocab_size=vocab_size,\r\n","      num_layers=num_layers,\r\n","      units=units,\r\n","      d_model=d_model,\r\n","      num_heads=num_heads,\r\n","      dropout=dropout,\r\n","  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\r\n","\r\n","  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\r\n","\r\n","  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"sw84YAwhpePk","executionInfo":{"status":"ok","timestamp":1614950641726,"user_tz":-420,"elapsed":205669,"user":{"displayName":"Nguy Huu Loc B1706606","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBw3CeyVXGS902KjXF0kx3M8aW-yGmbXac6bMN=s64","userId":"07558350334874798256"}}},"source":["def loss_function(y_true, y_pred):\r\n","  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\r\n","  \r\n","  loss = tf.keras.losses.SparseCategoricalCrossentropy(\r\n","      from_logits=True, reduction='none')(y_true, y_pred)\r\n","\r\n","  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\r\n","  loss = tf.multiply(loss, mask)\r\n","\r\n","  return tf.reduce_mean(loss)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"8VfZ7Z4ype9j","executionInfo":{"status":"ok","timestamp":1614950641727,"user_tz":-420,"elapsed":205667,"user":{"displayName":"Nguy Huu Loc B1706606","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBw3CeyVXGS902KjXF0kx3M8aW-yGmbXac6bMN=s64","userId":"07558350334874798256"}}},"source":["class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\r\n","\r\n","  def __init__(self, d_model, warmup_steps=4000):\r\n","    super(CustomSchedule, self).__init__()\r\n","    \r\n","    self.d_model = tf.constant(d_model,dtype=tf.float32)\r\n","    self.warmup_steps = warmup_steps\r\n","    \r\n","  def get_config(self):\r\n","        return {\"d_model\": self.d_model,\"warmup_steps\":self.warmup_steps}\r\n","    \r\n","  def __call__(self, step):\r\n","    arg1 = tf.math.rsqrt(step)\r\n","    arg2 = step * (self.warmup_steps**-1.5)\r\n","\r\n","    return tf.math.multiply(tf.math.rsqrt(self.d_model), tf.math.minimum(arg1, arg2))"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"CUHjJF2GphE7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614958847385,"user_tz":-420,"elapsed":5505,"user":{"displayName":"Nguy Huu Loc B1706606","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBw3CeyVXGS902KjXF0kx3M8aW-yGmbXac6bMN=s64","userId":"07558350334874798256"}},"outputId":"83f5aa6a-80cd-4c0d-dfd4-51af2ed15453"},"source":["# clear backend\r\n","tf.keras.backend.clear_session()\r\n","\r\n","learning_rate = CustomSchedule(D_MODEL)\r\n","\r\n","optimizer = tf.keras.optimizers.Adam(\r\n","    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\r\n","\r\n","def accuracy(y_true, y_pred):\r\n","  # ensure labels have shape (batch_size, MAX_LENGTH - 1)\r\n","  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\r\n","  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\r\n","\r\n","# initialize and compile model within strategy scope\r\n","with strategy.scope():\r\n","  model = transformer(\r\n","      vocab_size=VOCAB_SIZE,\r\n","      num_layers=NUM_LAYERS,\r\n","      units=UNITS,\r\n","      d_model=D_MODEL,\r\n","      num_heads=NUM_HEADS,\r\n","      dropout=DROPOUT)\r\n","\r\n","  model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\r\n","\r\n","model.summary()"],"execution_count":49,"outputs":[{"output_type":"stream","text":["Model: \"transformer\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","inputs (InputLayer)             [(None, None)]       0                                            \n","__________________________________________________________________________________________________\n","dec_inputs (InputLayer)         [(None, None)]       0                                            \n","__________________________________________________________________________________________________\n","enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n","__________________________________________________________________________________________________\n","encoder (Functional)            (None, None, 256)    3141376     inputs[0][0]                     \n","                                                                 enc_padding_mask[0][0]           \n","__________________________________________________________________________________________________\n","look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n","__________________________________________________________________________________________________\n","dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n","__________________________________________________________________________________________________\n","decoder (Functional)            (None, None, 256)    3668736     dec_inputs[0][0]                 \n","                                                                 encoder[0][0]                    \n","                                                                 look_ahead_mask[0][0]            \n","                                                                 dec_padding_mask[0][0]           \n","__________________________________________________________________________________________________\n","outputs (Dense)                 (None, None, 8153)   2095321     decoder[0][0]                    \n","==================================================================================================\n","Total params: 8,905,433\n","Trainable params: 8,905,433\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RLh6msXdqbhi","executionInfo":{"status":"ok","timestamp":1614971231257,"user_tz":-420,"elapsed":12359808,"user":{"displayName":"Nguy Huu Loc B1706606","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBw3CeyVXGS902KjXF0kx3M8aW-yGmbXac6bMN=s64","userId":"07558350334874798256"}},"outputId":"eb3f0f27-7b9f-41de-e28e-f8004bfbf4a7"},"source":["model.fit(dataset, epochs=200)\r\n","model.save_weights('saved_weights_tpu_2.h5')"],"execution_count":50,"outputs":[{"output_type":"stream","text":["Epoch 1/200\n","1501/1501 [==============================] - 97s 46ms/step - loss: 2.7995 - accuracy: 0.0489\n","Epoch 2/200\n","1501/1501 [==============================] - 60s 40ms/step - loss: 1.8031 - accuracy: 0.1008\n","Epoch 3/200\n","1501/1501 [==============================] - 60s 40ms/step - loss: 1.6768 - accuracy: 0.1092\n","Epoch 4/200\n","1501/1501 [==============================] - 60s 40ms/step - loss: 1.6207 - accuracy: 0.1137\n","Epoch 5/200\n","1501/1501 [==============================] - 60s 40ms/step - loss: 1.5786 - accuracy: 0.1172\n","Epoch 6/200\n","1501/1501 [==============================] - 60s 40ms/step - loss: 1.5510 - accuracy: 0.1197\n","Epoch 7/200\n","1501/1501 [==============================] - 60s 40ms/step - loss: 1.5310 - accuracy: 0.1214\n","Epoch 8/200\n","1501/1501 [==============================] - 60s 40ms/step - loss: 1.5166 - accuracy: 0.1229\n","Epoch 9/200\n","1501/1501 [==============================] - 60s 40ms/step - loss: 1.5042 - accuracy: 0.1241\n","Epoch 10/200\n","1501/1501 [==============================] - 60s 40ms/step - loss: 1.4940 - accuracy: 0.1251\n","Epoch 11/200\n","1501/1501 [==============================] - 60s 40ms/step - loss: 1.4852 - accuracy: 0.1258\n","Epoch 12/200\n","1501/1501 [==============================] - 60s 40ms/step - loss: 1.4780 - accuracy: 0.1266\n","Epoch 13/200\n","1501/1501 [==============================] - 60s 40ms/step - loss: 1.4713 - accuracy: 0.1272\n","Epoch 14/200\n","1501/1501 [==============================] - 60s 40ms/step - loss: 1.4658 - accuracy: 0.1278\n","Epoch 15/200\n","1501/1501 [==============================] - 60s 40ms/step - loss: 1.4606 - accuracy: 0.1284\n","Epoch 16/200\n","1501/1501 [==============================] - 60s 40ms/step - loss: 1.4557 - accuracy: 0.1288\n","Epoch 17/200\n","1501/1501 [==============================] - 61s 40ms/step - loss: 1.4513 - accuracy: 0.1293\n","Epoch 18/200\n","1501/1501 [==============================] - 60s 40ms/step - loss: 1.4468 - accuracy: 0.1297\n","Epoch 19/200\n","1501/1501 [==============================] - 60s 40ms/step - loss: 1.4435 - accuracy: 0.1302\n","Epoch 20/200\n","1501/1501 [==============================] - 60s 40ms/step - loss: 1.4399 - accuracy: 0.1305\n","Epoch 21/200\n","1501/1501 [==============================] - 61s 40ms/step - loss: 1.4369 - accuracy: 0.1309\n","Epoch 22/200\n","1501/1501 [==============================] - 60s 40ms/step - loss: 1.4336 - accuracy: 0.1311\n","Epoch 23/200\n","1501/1501 [==============================] - 61s 40ms/step - loss: 1.4309 - accuracy: 0.1315\n","Epoch 24/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.4277 - accuracy: 0.1319\n","Epoch 25/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.4257 - accuracy: 0.1321\n","Epoch 26/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.4235 - accuracy: 0.1323\n","Epoch 27/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.4209 - accuracy: 0.1326\n","Epoch 28/200\n","1501/1501 [==============================] - 60s 40ms/step - loss: 1.4188 - accuracy: 0.1329\n","Epoch 29/200\n","1501/1501 [==============================] - 60s 40ms/step - loss: 1.4167 - accuracy: 0.1332\n","Epoch 30/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.4144 - accuracy: 0.1332\n","Epoch 31/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.4125 - accuracy: 0.1334\n","Epoch 32/200\n","1501/1501 [==============================] - 60s 40ms/step - loss: 1.4108 - accuracy: 0.1337\n","Epoch 33/200\n","1501/1501 [==============================] - 60s 40ms/step - loss: 1.4094 - accuracy: 0.1340\n","Epoch 34/200\n","1501/1501 [==============================] - 60s 40ms/step - loss: 1.4073 - accuracy: 0.1340\n","Epoch 35/200\n","1501/1501 [==============================] - 60s 40ms/step - loss: 1.4060 - accuracy: 0.1342\n","Epoch 36/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.4042 - accuracy: 0.1345\n","Epoch 37/200\n","1501/1501 [==============================] - 61s 40ms/step - loss: 1.4019 - accuracy: 0.1346\n","Epoch 38/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.4009 - accuracy: 0.1348\n","Epoch 39/200\n","1501/1501 [==============================] - 61s 40ms/step - loss: 1.3996 - accuracy: 0.1350\n","Epoch 40/200\n","1501/1501 [==============================] - 61s 40ms/step - loss: 1.3986 - accuracy: 0.1351\n","Epoch 41/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3972 - accuracy: 0.1352\n","Epoch 42/200\n","1501/1501 [==============================] - 61s 40ms/step - loss: 1.3955 - accuracy: 0.1354\n","Epoch 43/200\n","1501/1501 [==============================] - 60s 40ms/step - loss: 1.3944 - accuracy: 0.1356\n","Epoch 44/200\n","1501/1501 [==============================] - 60s 40ms/step - loss: 1.3927 - accuracy: 0.1356\n","Epoch 45/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3914 - accuracy: 0.1358\n","Epoch 46/200\n","1501/1501 [==============================] - 60s 40ms/step - loss: 1.3909 - accuracy: 0.1360\n","Epoch 47/200\n","1501/1501 [==============================] - 61s 40ms/step - loss: 1.3891 - accuracy: 0.1360\n","Epoch 48/200\n","1501/1501 [==============================] - 61s 40ms/step - loss: 1.3885 - accuracy: 0.1362\n","Epoch 49/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3871 - accuracy: 0.1363\n","Epoch 50/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3861 - accuracy: 0.1365\n","Epoch 51/200\n","1501/1501 [==============================] - 61s 40ms/step - loss: 1.3853 - accuracy: 0.1365\n","Epoch 52/200\n","1501/1501 [==============================] - 60s 40ms/step - loss: 1.3841 - accuracy: 0.1367\n","Epoch 53/200\n","1501/1501 [==============================] - 60s 40ms/step - loss: 1.3835 - accuracy: 0.1368\n","Epoch 54/200\n","1501/1501 [==============================] - 60s 40ms/step - loss: 1.3821 - accuracy: 0.1369\n","Epoch 55/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3811 - accuracy: 0.1371\n","Epoch 56/200\n","1501/1501 [==============================] - 60s 40ms/step - loss: 1.3803 - accuracy: 0.1371\n","Epoch 57/200\n","1501/1501 [==============================] - 60s 40ms/step - loss: 1.3790 - accuracy: 0.1372\n","Epoch 58/200\n","1501/1501 [==============================] - 60s 40ms/step - loss: 1.3784 - accuracy: 0.1373\n","Epoch 59/200\n","1501/1501 [==============================] - 60s 40ms/step - loss: 1.3776 - accuracy: 0.1374\n","Epoch 60/200\n","1501/1501 [==============================] - 60s 40ms/step - loss: 1.3766 - accuracy: 0.1375\n","Epoch 61/200\n","1501/1501 [==============================] - 60s 40ms/step - loss: 1.3764 - accuracy: 0.1375\n","Epoch 62/200\n","1501/1501 [==============================] - 61s 40ms/step - loss: 1.3751 - accuracy: 0.1377\n","Epoch 63/200\n","1501/1501 [==============================] - 60s 40ms/step - loss: 1.3742 - accuracy: 0.1378\n","Epoch 64/200\n","1501/1501 [==============================] - 61s 40ms/step - loss: 1.3736 - accuracy: 0.1379\n","Epoch 65/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3727 - accuracy: 0.1379\n","Epoch 66/200\n","1501/1501 [==============================] - 61s 40ms/step - loss: 1.3721 - accuracy: 0.1381\n","Epoch 67/200\n","1501/1501 [==============================] - 61s 40ms/step - loss: 1.3714 - accuracy: 0.1381\n","Epoch 68/200\n","1501/1501 [==============================] - 61s 40ms/step - loss: 1.3707 - accuracy: 0.1382\n","Epoch 69/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3696 - accuracy: 0.1383\n","Epoch 70/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3694 - accuracy: 0.1384\n","Epoch 71/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3689 - accuracy: 0.1385\n","Epoch 72/200\n","1501/1501 [==============================] - 61s 40ms/step - loss: 1.3674 - accuracy: 0.1386\n","Epoch 73/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3674 - accuracy: 0.1386\n","Epoch 74/200\n","1501/1501 [==============================] - 61s 40ms/step - loss: 1.3669 - accuracy: 0.1388\n","Epoch 75/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3663 - accuracy: 0.1388\n","Epoch 76/200\n","1501/1501 [==============================] - 61s 40ms/step - loss: 1.3648 - accuracy: 0.1388\n","Epoch 77/200\n","1501/1501 [==============================] - 61s 40ms/step - loss: 1.3646 - accuracy: 0.1389\n","Epoch 78/200\n","1501/1501 [==============================] - 61s 40ms/step - loss: 1.3642 - accuracy: 0.1391\n","Epoch 79/200\n","1501/1501 [==============================] - 61s 40ms/step - loss: 1.3634 - accuracy: 0.1390\n","Epoch 80/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3625 - accuracy: 0.1391\n","Epoch 81/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3620 - accuracy: 0.1392\n","Epoch 82/200\n","1501/1501 [==============================] - 61s 40ms/step - loss: 1.3617 - accuracy: 0.1393\n","Epoch 83/200\n","1501/1501 [==============================] - 61s 40ms/step - loss: 1.3610 - accuracy: 0.1393\n","Epoch 84/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3609 - accuracy: 0.1394\n","Epoch 85/200\n","1501/1501 [==============================] - 61s 40ms/step - loss: 1.3602 - accuracy: 0.1395\n","Epoch 86/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3600 - accuracy: 0.1395\n","Epoch 87/200\n","1501/1501 [==============================] - 61s 40ms/step - loss: 1.3591 - accuracy: 0.1396\n","Epoch 88/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3587 - accuracy: 0.1396\n","Epoch 89/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3585 - accuracy: 0.1398\n","Epoch 90/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3574 - accuracy: 0.1396\n","Epoch 91/200\n","1501/1501 [==============================] - 60s 40ms/step - loss: 1.3572 - accuracy: 0.1398\n","Epoch 92/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3572 - accuracy: 0.1398\n","Epoch 93/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3563 - accuracy: 0.1399\n","Epoch 94/200\n","1501/1501 [==============================] - 61s 40ms/step - loss: 1.3562 - accuracy: 0.1400\n","Epoch 95/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3551 - accuracy: 0.1400\n","Epoch 96/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3551 - accuracy: 0.1401\n","Epoch 97/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3547 - accuracy: 0.1401\n","Epoch 98/200\n","1501/1501 [==============================] - 61s 40ms/step - loss: 1.3541 - accuracy: 0.1402\n","Epoch 99/200\n","1501/1501 [==============================] - 61s 40ms/step - loss: 1.3537 - accuracy: 0.1402\n","Epoch 100/200\n","1501/1501 [==============================] - 61s 40ms/step - loss: 1.3533 - accuracy: 0.1402\n","Epoch 101/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3534 - accuracy: 0.1403\n","Epoch 102/200\n","1501/1501 [==============================] - 61s 40ms/step - loss: 1.3526 - accuracy: 0.1403\n","Epoch 103/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3521 - accuracy: 0.1405\n","Epoch 104/200\n","1501/1501 [==============================] - 60s 40ms/step - loss: 1.3515 - accuracy: 0.1404\n","Epoch 105/200\n","1501/1501 [==============================] - 60s 40ms/step - loss: 1.3514 - accuracy: 0.1406\n","Epoch 106/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3512 - accuracy: 0.1406\n","Epoch 107/200\n","1501/1501 [==============================] - 61s 40ms/step - loss: 1.3508 - accuracy: 0.1406\n","Epoch 108/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3503 - accuracy: 0.1407\n","Epoch 109/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3501 - accuracy: 0.1406\n","Epoch 110/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3501 - accuracy: 0.1407\n","Epoch 111/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3488 - accuracy: 0.1408\n","Epoch 112/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3491 - accuracy: 0.1408\n","Epoch 113/200\n","1501/1501 [==============================] - 61s 40ms/step - loss: 1.3485 - accuracy: 0.1409\n","Epoch 114/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3485 - accuracy: 0.1409\n","Epoch 115/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3482 - accuracy: 0.1409\n","Epoch 116/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3475 - accuracy: 0.1410\n","Epoch 117/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3471 - accuracy: 0.1410\n","Epoch 118/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3468 - accuracy: 0.1411\n","Epoch 119/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3461 - accuracy: 0.1411\n","Epoch 120/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3462 - accuracy: 0.1411\n","Epoch 121/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3460 - accuracy: 0.1413\n","Epoch 122/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3453 - accuracy: 0.1412\n","Epoch 123/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3454 - accuracy: 0.1412\n","Epoch 124/200\n","1501/1501 [==============================] - 61s 40ms/step - loss: 1.3448 - accuracy: 0.1414\n","Epoch 125/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3448 - accuracy: 0.1413\n","Epoch 126/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3441 - accuracy: 0.1414\n","Epoch 127/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3437 - accuracy: 0.1415\n","Epoch 128/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3438 - accuracy: 0.1415\n","Epoch 129/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3430 - accuracy: 0.1414\n","Epoch 130/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3435 - accuracy: 0.1415\n","Epoch 131/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3428 - accuracy: 0.1416\n","Epoch 132/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3424 - accuracy: 0.1416\n","Epoch 133/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3420 - accuracy: 0.1417\n","Epoch 134/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3417 - accuracy: 0.1417\n","Epoch 135/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3412 - accuracy: 0.1418\n","Epoch 136/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3413 - accuracy: 0.1418\n","Epoch 137/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3412 - accuracy: 0.1418\n","Epoch 138/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3404 - accuracy: 0.1419\n","Epoch 139/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3404 - accuracy: 0.1419\n","Epoch 140/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3400 - accuracy: 0.1418\n","Epoch 141/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3397 - accuracy: 0.1420\n","Epoch 142/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3394 - accuracy: 0.1420\n","Epoch 143/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3393 - accuracy: 0.1420\n","Epoch 144/200\n","1501/1501 [==============================] - 61s 40ms/step - loss: 1.3391 - accuracy: 0.1421\n","Epoch 145/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3383 - accuracy: 0.1421\n","Epoch 146/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3381 - accuracy: 0.1421\n","Epoch 147/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3379 - accuracy: 0.1421\n","Epoch 148/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3380 - accuracy: 0.1421\n","Epoch 149/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3377 - accuracy: 0.1422\n","Epoch 150/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3374 - accuracy: 0.1422\n","Epoch 151/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3374 - accuracy: 0.1423\n","Epoch 152/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3364 - accuracy: 0.1423\n","Epoch 153/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3368 - accuracy: 0.1423\n","Epoch 154/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3359 - accuracy: 0.1423\n","Epoch 155/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3362 - accuracy: 0.1423\n","Epoch 156/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3358 - accuracy: 0.1424\n","Epoch 157/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3354 - accuracy: 0.1425\n","Epoch 158/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3353 - accuracy: 0.1426\n","Epoch 159/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3351 - accuracy: 0.1425\n","Epoch 160/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3347 - accuracy: 0.1425\n","Epoch 161/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3348 - accuracy: 0.1425\n","Epoch 162/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3344 - accuracy: 0.1426\n","Epoch 163/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3337 - accuracy: 0.1426\n","Epoch 164/200\n","1501/1501 [==============================] - 62s 42ms/step - loss: 1.3336 - accuracy: 0.1427\n","Epoch 165/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3332 - accuracy: 0.1427\n","Epoch 166/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3332 - accuracy: 0.1426\n","Epoch 167/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3336 - accuracy: 0.1427\n","Epoch 168/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3328 - accuracy: 0.1427\n","Epoch 169/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3328 - accuracy: 0.1428\n","Epoch 170/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3330 - accuracy: 0.1428\n","Epoch 171/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3322 - accuracy: 0.1429\n","Epoch 172/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3321 - accuracy: 0.1429\n","Epoch 173/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3316 - accuracy: 0.1429\n","Epoch 174/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3318 - accuracy: 0.1429\n","Epoch 175/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3318 - accuracy: 0.1429\n","Epoch 176/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3316 - accuracy: 0.1429\n","Epoch 177/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3311 - accuracy: 0.1430\n","Epoch 178/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3306 - accuracy: 0.1429\n","Epoch 179/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3306 - accuracy: 0.1430\n","Epoch 180/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3309 - accuracy: 0.1431\n","Epoch 181/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3299 - accuracy: 0.1432\n","Epoch 182/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3299 - accuracy: 0.1431\n","Epoch 183/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3292 - accuracy: 0.1432\n","Epoch 184/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3297 - accuracy: 0.1432\n","Epoch 185/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3295 - accuracy: 0.1432\n","Epoch 186/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3292 - accuracy: 0.1432\n","Epoch 187/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3289 - accuracy: 0.1433\n","Epoch 188/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3286 - accuracy: 0.1432\n","Epoch 189/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3281 - accuracy: 0.1433\n","Epoch 190/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3283 - accuracy: 0.1434\n","Epoch 191/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3276 - accuracy: 0.1433\n","Epoch 192/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3275 - accuracy: 0.1433\n","Epoch 193/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3271 - accuracy: 0.1434\n","Epoch 194/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3274 - accuracy: 0.1435\n","Epoch 195/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3275 - accuracy: 0.1434\n","Epoch 196/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3268 - accuracy: 0.1434\n","Epoch 197/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3268 - accuracy: 0.1435\n","Epoch 198/200\n","1501/1501 [==============================] - 61s 41ms/step - loss: 1.3267 - accuracy: 0.1435\n","Epoch 199/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3266 - accuracy: 0.1436\n","Epoch 200/200\n","1501/1501 [==============================] - 62s 41ms/step - loss: 1.3263 - accuracy: 0.1434\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3ctfXGQurVza","executionInfo":{"status":"ok","timestamp":1614957169113,"user_tz":-420,"elapsed":6733018,"user":{"displayName":"Nguy Huu Loc B1706606","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBw3CeyVXGS902KjXF0kx3M8aW-yGmbXac6bMN=s64","userId":"07558350334874798256"}}},"source":["import re\r\n","def textPreprocess(text):\r\n","  text = text.lower()\r\n","  text = re.sub(r\"[)(@=_+*&^.?#$!,:-]\",\" \", text)\r\n","  text = re.sub(r\"[^\\w]\",\" \",text)\r\n","  text = text.replace(\"'\",\"\")\r\n","  text = text.replace('\"','')\r\n","  text = text.strip()\r\n","  text = \" \".join(text.split())\r\n","  \r\n","  return text"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"QbSSRM9_vWle","executionInfo":{"status":"ok","timestamp":1614957169114,"user_tz":-420,"elapsed":6733015,"user":{"displayName":"Nguy Huu Loc B1706606","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBw3CeyVXGS902KjXF0kx3M8aW-yGmbXac6bMN=s64","userId":"07558350334874798256"}}},"source":["def evaluate(sentence, model):\r\n","  sentence = textPreprocess(sentence)\r\n","\r\n","  sentence = tf.expand_dims(\r\n","      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\r\n","  \r\n","  output = tf.expand_dims(START_TOKEN, 0)\r\n","\r\n","  for i in range(MAX_LENGTH):\r\n","    predictions = model(inputs=[sentence, output], training=False)\r\n","\r\n","    # select the last word from the seq_len dimension\r\n","    predictions = predictions[:, -1:, :]\r\n","    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\r\n","\r\n","    # return the result if the predicted_id is equal to the end token\r\n","    if tf.equal(predicted_id, END_TOKEN[0]):\r\n","      break\r\n","\r\n","    # concatenated the predicted_id to the output which is given to the decoder\r\n","    # as its input.\r\n","    output = tf.concat([output, predicted_id], axis=-1)\r\n","\r\n","  return tf.squeeze(output, axis=0)\r\n","\r\n","\r\n","def predict(sentence,model):\r\n","  prediction = evaluate(sentence,model)\r\n","\r\n","  predicted_sentence = tokenizer.decode(\r\n","      [i for i in prediction if i < tokenizer.vocab_size])\r\n","\r\n","  print('Bot: {}'.format(predicted_sentence))\r\n","\r\n","  return predicted_sentence"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xj5X9EKGv5FP","executionInfo":{"status":"ok","timestamp":1614957169115,"user_tz":-420,"elapsed":6733011,"user":{"displayName":"Nguy Huu Loc B1706606","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBw3CeyVXGS902KjXF0kx3M8aW-yGmbXac6bMN=s64","userId":"07558350334874798256"}}},"source":["# def accuracy(y_true, y_pred):\n","#   # ensure labels have shape (batch_size, MAX_LENGTH - 1)\n","#   y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n","#   return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n","# learning_rate = CustomSchedule(D_MODEL)\n","# optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n","# loaded_model_gpu = transformer(\n","#       vocab_size=VOCAB_SIZE,\n","#       num_layers=NUM_LAYERS,\n","#       units=UNITS,\n","#       d_model=D_MODEL,  \n","#       num_heads=NUM_HEADS,\n","#       dropout=DROPOUT)\n","\n","# loaded_model_gpu.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n","# loaded_model_gpu.load_weights('saved_weights_gpu.h5')"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"BnR7XXvF3ouT","executionInfo":{"status":"ok","timestamp":1614957172520,"user_tz":-420,"elapsed":6736413,"user":{"displayName":"Nguy Huu Loc B1706606","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBw3CeyVXGS902KjXF0kx3M8aW-yGmbXac6bMN=s64","userId":"07558350334874798256"}}},"source":["def accuracy(y_true, y_pred):\r\n","  # ensure labels have shape (batch_size, MAX_LENGTH - 1)\r\n","  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\r\n","  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\r\n","learning_rate = CustomSchedule(D_MODEL)\r\n","optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\r\n","loaded_model_tpu = transformer(\r\n","      vocab_size=VOCAB_SIZE,\r\n","      num_layers=NUM_LAYERS,\r\n","      units=UNITS,\r\n","      d_model=D_MODEL,  \r\n","      num_heads=NUM_HEADS,\r\n","      dropout=DROPOUT)\r\n","\r\n","loaded_model_tpu.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\r\n","loaded_model_tpu.load_weights('saved_weights_tpu_1.h5')"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":782},"id":"XQgrfdy83u6q","executionInfo":{"status":"error","timestamp":1614957899132,"user_tz":-420,"elapsed":7463010,"user":{"displayName":"Nguy Huu Loc B1706606","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBw3CeyVXGS902KjXF0kx3M8aW-yGmbXac6bMN=s64","userId":"07558350334874798256"}},"outputId":"ae8e7d16-6e63-4504-c92a-6929e2d53f1d"},"source":["while True:\r\n","  key = input(\"You: \")\r\n","  if key != 'tm bit':\r\n","    sentence = predict(key, loaded_model_tpu)\r\n","  else:\r\n","    sentence = predict(key, loaded_model_tpu)\r\n","    break\r\n","  print('')"],"execution_count":35,"outputs":[{"output_type":"stream","text":["You: hi\n","Bot: Ti khng bit phi lm g na\n","\n","You: cho\n","Bot: Ti khng bit anh ang ni g na\n","\n","You: cho bn\n","Bot: Ti s gi cho bn sau\n","\n","You: xin cho\n","Bot: Ti khng bit anh ang ni g na\n","\n","You: cho \n","Bot: Ti khng bit anh ang ni g na\n","\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \"\"\"\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-35-20679c9b0268>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'tm bit'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaded_model_tpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}